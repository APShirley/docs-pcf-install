---
title: Restoring Pivotal Cloud Foundry from Backup with BBR
owner: RelEng
---

<strong><%= modified_date %></strong>

<style>
    .note.warning {
       background-color: #fdd;
       border-color: #fbb
  	          }
    .note.warning:before {
       color: #f99;
		         }
</style>

<p class="note"><strong>Note</strong>: BBR is a beta feature in PCF v1.11.</p>

This topic describes the procedure for restoring your critical backend Pivotal Cloud Foundry (PCF) components with BOSH Backup and Restore (BBR), a command-line tool for backing up and restoring BOSH deployments. To perform the procedures in this topic, you must have backed up Pivotal Cloud Foundry (PCF) by following the steps in the [Backing Up Pivotal Cloud Foundry with BBR](backup-pcf-bbr.html) topic.

To restore PCF manually, see the <a href="restore-pcf.html">Restoring Pivotal Cloud Foundry Manually from Backup</a> topic.

<p class="note"><strong>Note</strong>: You can only use BBR to back up PCF v1.11 and later. To restore earlier versions of PCF, perform the <a href="restore-pcf.html">manual procedures</a>.</p>

<p class="note warning"><strong>Note</strong>: BBR restore is a destructive operation. These instructions are for recreating PCF after a disaster such as SAN corruption. If the restore fails, the new environment may be left in an unusable state and needing to be reprovisioned. </p>

The procedures described in this topic prepare your environment for PCF, deploy Ops Manager, import your installation settings, and use BBR to restore your PCF components.

## <a id='prepare-env'></a>Step 1: Prepare Your Environment

Prepare your environment for PCF by following the instructions specific to your IaaS in <a href='../../installing/index.html'>Installing Pivotal Cloud Foundry</a>.

## <a id='deploy-import'></a>Step 2: Deploy Ops Manager and Import Installation Settings ##

1. Perform the procedures for your IaaS to deploy Ops Manager:
  * [Launching an Ops Manager Director Instance on AWS](../cloudform-om-deploy.html)
  * [Launching an Ops Manager Director Instance on Azure](../azure-arm-template.html)
  * [Launching an Ops Manager Director Instance on GCP](../gcp-om-deploy.html)
  * [Provisioning the OpenStack Infrastructure](../openstack-setup.html)
  * [Deploying Operations Manager to vSphere](../deploying-vm.html)

1. Access your new Ops Manager by navigating to `YOUR-OPS-MAN-FQDN` in a browser.

1. On the **Welcome to Ops Manager** page, click **Import Existing Installation**.

    <%= image_tag("../images/upgrading/welcome.png") %>

1. In the import panel, perform the following tasks:
  * Enter your **Decryption Passphrase**.
  * Click **Choose File** and browse to the installation zip file that you exported in the <a href='./backup-pcf-bbr.html#export'>Step 3: Export Installation Settings</a> section of the <i>Backing Up Pivotal Cloud Foundry with BBR</i> topic.

    <%= image_tag("../images/upgrading/decryption_passphrase.png") %>

1. Click **Import**.

    <p class="note"><strong>Note</strong>:
      Some browsers do not provide feedback on the status of the import process,
      and may appear to hang.</p>

1. A **Successfully imported installation** message appears upon completion.

    <%= image_tag("../images/upgrading/success.png") %>

## <a id="bosh-state"></a> Step 3: Remove BOSH State File

1. SSH into your Ops Manager VM. For more information, see the [SSH into Ops Manager](../trouble-advanced.html#ssh) section of the <em>Advanced Troubleshooting with the BOSH CLI</em> topic.
1. On the Ops Manager VM, delete the `/var/tempest/workspaces/default/deployments/bosh-state.json` file:
  <pre class="terminal">
  $ rm /var/tempest/workspaces/default/deployments/bosh-state.json
  </pre>
1. Navigate to `YOUR-OPS-MAN-FQDN` in a browser and log into Ops Manager.
1. For each tile that requires one, upload the required stemcell.
1. Do not click **Apply Changes**. Instead, perform the steps in the [Applying Changes to Ops Manager Director](../deploy-ops-man-director.html) topic to use the Ops Manager API to only deploy the Ops Manager Director.

## <a id="artifacts-jumpbox"></a> Step 4: Transfer Artifacts to Jumpbox

In the [Step 9: Back Up Your Deployment](./backup-pcf-bbr.html#bbr-backup) section of the <em>Backing Up Pivotal Cloud Foundry with BBR</em> topic, you moved the TAR and metadata files of the backup artifact off your jumpbox to your preferred storage space. Now you must transfer those files back to your jumpbox.

For instance, you could SCP the backup artifact to your jumpbox:
  <pre class="terminal">$ scp LOCAL\_PATH\_TO\_BACKUP\_ARTIFACT JUMPBOX\_USER/JUMPBOX\_ADDRESS</pre>

## <a id="retrieve"></a> Step 5: Retrieve BOSH Director Address and Credentials

Perform the following steps to retrieve the IP address of your BOSH Director and the credentials for logging in:

<%= partial 'bosh_target_director_bbr' %>

## <a id='restore-bosh'></a> Step 6: Restore the BOSH Director

1. Navigate to the Ops Manager Installation Dashboard.
1. Click the Ops Manager tile.
1. Click the **Credentials** tab.
1. Locate **Bbr Ssh Credentials** and click **Link to Credential** next to it.
1. Copy the value for `private_key_pem`, beginning with `"-----BEGIN RSA PRIVATE KEY-----"`.
1. SSH into your jumpbox.
1. Run the following command to reformat the key and save it to a file called `PRIVATE_KEY` in the current directory, pasting in the contents of your private key for `YOUR_PRIVATE_KEY`:
  <pre class="terminal">
  printf -- "YOUR\_PRIVATE\_KEY" > PRIVATE_KEY
  </pre>
1. Ensure the BOSH Director backup artifact is in the folder you will run BBR from.
1. Run the BBR restore command from your jumpbox to restore the BOSH Director:
  <pre class="terminal">
  $ nohup bbr director \
      --private-key-path PRIVATE\_KEY \
      --username bbr \
      --host HOST \
      restore \
        --artifact-path PATH\_TO\_DIRECTOR\_BACKUP
  </pre>
  Use the optional `--debug` flag to enable debug logs. See the [Logging](backup-pcf-bbr.html#logging) section of the <em>Backing Up Pivotal Cloud Foundry with BBR</em> topic for more information.
  <br><br>
  Replace the placeholder values as follows:
  * `PATH_TO_DIRECTOR_BACKUP`: This is the path to the Director backup you want to restore.
  * `PATH_TO_PRIVATE_KEY`: This is the path to the private key file you created above.
  * `HOST`: This is the address of the BOSH Director. If the BOSH Director is public, this will be a URL, such as `https://my-bosh.xxx.cf-app.com`. Otherwise, it will be the `BOSH_DIRECTOR_IP`, which you retrieved in the [Step 5: Retrieve BOSH Director Address and Credentials](#retrieve) section.

<p class="note"><strong>Note</strong>: The BBR restore command can take a long time to complete. Pivotal recommends you run it independently of the SSH session, so that the process can continue running even if your connection to the jumpbox fails. The command above uses <code>nohup</code> but you could also run the command in a <code>screen</code> or <code>tmux</code> session.</p>

If the commands completes successfully, continue to [Step 8: Remove Stale Cloud IDs for All Deployments](#bosh-cck).

If the command fails, do the following:

1. Ensure all the parameters in the command are set.
1. Ensure the BOSH Director credentials are valid.
1. Ensure the specified deployment exists.
1. Ensure the source deployment is incompatible with the target deployment.
1. Ensure that the jumpbox can reach the BOSH Director.

## <a id='identify-deployment'></a> Step 7: Identify Your Deployment

After logging in to your BOSH Director, run `bosh deployments` to identify the name of the BOSH deployment that contains PCF:

<pre class='terminal'>
$ bosh -e DIRECTOR_IP --ca-cert /var/tempest/workspaces/default/root_ca_certificate deployments

Name                     Release(s)
cf-example               push-apps-manager-release/661.1.24
                         cf-backup-and-restore/0.0.1
                         binary-buildpack/1.0.11
                         capi/1.28.0
                         cf-autoscaling/91
                         cf-mysql/35
                         ...
</pre>

In the above example, the name of the BOSH deployment that contains PCF is `cf-example`.

## <a id="bosh-cck"></a> Step 8: Remove Stale Cloud IDs for All Deployments

For every deployment in the BOSH Director, run the following command:

<pre class="terminal">
$ bosh -e DIRECTOR_IP -d DEPLOYMENT_NAME -n cck \
  --resolution delete_disk_reference \
  --resolution delete_vm_reference
</pre>

This reconciles the BOSH Director's internal state with the state in the IaaS. You can use the list of deployments returned in [Step 7: Identify Your Deployment](#identify-deployment).

If the <code>bosh cck</code> command does not successfully delete disk references and you see a message similar to the following:
<pre class="terminal">
Scanning 19 persistent disks: 19 OK, 0 missing ...
</pre>
Follow the additional instructions in the <a href="#removing-disks">Remove Unused Disks</a> section below.

## <a id='redeploy-ert'></a> Step 9: Redeploy Elastic Runtime
1. Reupload the stemcell used by the ERT via the bosh cli:
  <pre class="terminal">
  $ bosh -e BOSH\_DIRECTOR\_IP \
      -d DEPLOYMENT\_NAME \
      --ca-cert PATH\_TO\_BOSH\_SERVER\_CERT \
      upload-stemcell --fix STEMCELL\_URL
  </pre>
1. From the Ops Manager Installation Dashboard, navigate to **Pivotal Elastic Runtime > Resource Config**.
1. Ensure the number of instances for MySQL Server is set to `1`.
  <p class="note warning"><strong>Note</strong>: Restore will fail if there is not exactly one MySQL Server instance deployed.</p>
1. Navigate to Ops Manager Installation Dashboard and click **Apply Changes** to redeploy.

## <a id='restore-ert'></a> Step 10: Restore Elastic Runtime

1. Run the BBR restore command from your jumpbox to restore Elastic Runtime:
<pre class="terminal">
$ BOSH\_CLIENT\_SECRET=BOSH_PASSWORD \
      bbr deployment \
        --target BOSH\_DIRECTOR\_IP \
        --username BOSH\_CLIENT \
        --deployment DEPLOYMENT\_NAME \
        --ca-cert PATH\_TO\_BOSH\_SERVER\_CERT \
        restore \
          --artifact-path PATH\_TO\_ERT\_BACKUP
</pre>

    Replace the placeholder values as follows:
    * `BOSH_CLIENT`, `BOSH_CLIENT_SECRET`: Use the BOSH UAA user provided in  **Pivotal Ops Manager > Credentials > Uaa Bbr Client Credentials**.
    * `BOSH_DIRECTOR_IP`: You retrieved this value in the [Step 5: Retrieve BOSH Director Address and Credentials](#retrieve) section.
    * `DEPLOYMENT-NAME`: You retrieved this value in the [Step 7: Identify Your Deployment](#identify-deployment) section.
    * `PATH_TO_BOSH_SERVER_CERT`: This is the path to the BOSH Director’s Certificate Authority (CA) certificate, if the certificate is not verifiable by the local machine’s certificate chain.
    * `PATH_TO_ERT_BACKUP`: This is the path to the Elastic Runtime backup you want to restore.

1. If you have container-to-container networking enabled in the Elastic Runtime, perform the following steps after restoring Elastic Runtime:
  1. Retrieve the MySQL admin password from **Pivotal Elastic Runtime > Credentials > Mysql Admin Credentials**
  1. SSH onto the `mysql` VM.
  1. Run `sudo /var/vcap/packages/mariadb/bin/mysql -u root -p` and enter the admin password.
  1. At the MySQL prompt, enter `use silk; drop table subnets; drop table gorp_migrations;`.
  1. SSH onto each `diego_database` VM and run `sudo monit restart silk-controller`.

1. If desired, scale the MySQL Server job back up to its previous number of instances by going to the Ops Manager Installation Dashboard and navigating to **Pivotal Elastic Runtime > Resource Config** and clicking **Apply Changes** to deploy.

1. Validate your restored PCF by performing the steps in the [Step 11: (Optional) Validate Your Backup](backup-pcf-bbr.html#validate-backup) section of the <em>Backing Up Pivotal Cloud Foundry with BBR</em>.

## <a id='removing-disks'></a> Appendix A: Remove Unused Disks

If `bosh cck` does not clean up all disk references, there are disks from a previous deployment in the IaaS which will prevent recreated deployments from working.

To clean up these disks, perform one of the following steps:

* Target the redeployed BOSH Director using the BOSH CLI, list the deployments, and delete each deployment using `bosh -d DEPLOYMENT_NAME delete-deployment`.
* Log into your IaaS account and delete the disks manually.

<p class="note warning"><strong>Note</strong>: This is a very destructive operation.</p>

Once the disks are deleted, continue with [Step 8: Remove Stale Cloud IDs for All Deployments](#bosh-cck).

## <a id="troubleshooting"></a> Appendix B: Troubleshooting

### Scenario

During BBR restore, restoring job `mysql-restore` fails with:

<pre class="terminal">
1 error occurred:

* restore script for job mysql-restore failed on mysql/0.
...
Monit start failed: Timed out waiting for monit: 2m0s
</pre>

This happens when `mariadb` fails to start within the timeout period -- it will end up in "Execution Failed" state and `monit` will never try to start it again. To validate that this:

1. `bosh ssh` into the MySQL VM.
1. Run `ps aux | grep mariadb` and check that the `mariadb` process is running.
1. Run `sudo monit summary` and check that it reports `mariadb_ctrl` is not running.

###  Solution

1. `bosh ssh` into the MySQL VM.
1. Run `monit unmonitor`
1. Run `monit monitor` -- after a few minutes, `monit summary` should report that all the processes are running.
1. Re-attempt the restore.
