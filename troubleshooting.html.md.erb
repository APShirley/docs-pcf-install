#encoding: utf-8
---
title: Pivotal CF Troubleshooting Guide
---

This guide provides help with diagnosing and resolving issues encountered
during a Pivotal CF install.
For help troubleshooting issues that are specific to Pivotal CF deployments on
VMware vSphere, refer to the the topic on [Troubleshooting Ops Manager for VMware vSphere](./troubleshooting-vsphere.html).

An install or update can fail for many reasons.
Fortunately, the system tends to heal or work around hardware or network faults.
By the time you click the `Install` or `Apply Changes` button again, the
problem may be resolved.

Some failures produce only generic errors like `Exited with 1`.
In cases like this, where a failure is not accompanied by useful information,
it's a good idea to click the `Install` or `Apply Changes` button.
Even doing so repeatedly does no harm.

When the system _does_ provide informative evidence, review the [Common Problems](#common_probs) section at the end of this guide to see if your
problem is covered there.

Besides whether products install successfully or not, an important area to
consider when troubleshooting is communication between VMs deployed by Pivotal
CF.
Depending on what products you install, communication takes the form of
messaging, routing, or both.
If they go wrong, an installation can fail.
For example, in an Elastic Runtime installation the Pivotal CF VM tries to push
a test application to the cloud during post-installation testing.
The installation fails if the resulting traffic cannot be routed to the HA
Proxy load balancer.

## <a id='debug'></a>Viewing the debug Endpoint ##

The debug endpoint is a web page that provides information useful in
troubleshooting.
If you have superuser privileges and can view the Ops Manager Installation
Dashboard, you can access the debug endpoint.

* In a browser, open the URL:

    `https://<Ops_Manager_IP_address>/debug`

The debug endpoint offers three links:

* *Files* allows you to view the YAML files that Ops Manager uses to configure
products that you install.
The most important YAML file, `installation.yml`, provides networking settings
and describes `microbosh`.
In this case, `microbosh` is the VM whose BOSH Director component is used by
Ops Manager to perform installations and updates of Elastic Runtime and other
products.
* *Components* describes the components in detail.
* *Rails log* shows errors thrown by the VM where the Ops Manager web
application (a Rails application) is running, as recorded in the
`production.log` file.
See the next section to learn how to explore other logs.

## <a id='component_logs'></a>Viewing Logs for Elastic Runtime Components ##

To troubleshoot specific Elastic Runtime components by viewing their log files, browse to the Ops Manager interface and follow the procedure below.

1. In Ops Manager, browse to the **Pivotal Elastic Runtime > Status** tab. In the **Job** column, locate the component of interest.
1. In the **Logs** column for the component, click the download icon.

    <%= image_tag("troubleshooting/status.png") %>

1. Browse to the **Pivotal Elastic Runtime > Logs** tab.

    <%= image_tag("troubleshooting/logs.png") %>

1. Once the zip file corresponding to the component of interest moves to the **Downloaded** list, click the linked file path to download the zip file.
1. Once the download completes, unzip the file.

The contents of the log directory vary depending on which component you view. For example, the DEA log directory contains subdirectories for the `dea_logging_agent`, `dea_next`, `monit`, and `warden` processes. To view the standard error stream for `warden`, download the DEA logs and open `dea.0.job > warden > warden.stderr.log`.

##<a id='view_in_terminal'></a>Viewing Web Application and BOSH Failure Logs in a Terminal Window ##

You can obtain diagnostic information from the Operations Manager by logging
in to the VM where it is running. To log in to the Operations Manager VM, you need the following information:

* The IP address of the Pivotal CF VM shown in the `Settings` tab of the Ops
Manager Director tile.
* Your **import credentials**. Import credentials are the username and password
used to import the Pivotal CF `.ova` or `.ovf` file into your virtualization
system.

Complete the following steps to log in to the Operations Manager VM:

1. Open a terminal window.
1. Run `ssh <import_username>@<Pivotal_CF_VM_IP_address>` to connect to the the Pivotal CF installation VM.
1. Enter your import password when prompted.
1. Change directories to the home directory of the web application:

    `cd /home/tempest-web/tempest/web/`

1. You are now in a position to explore whether things are as they should be
within the web application.
<br /><br />
    You can also verify that the `microbosh` component is successfully
installed.
A successful MicroBOSH installation is required to install Elastic Runtime and any products like databases and messaging services.

1. Change directories to the BOSH installation log home:

    `cd /var/tempest/workspaces/default/deployments/micro`

1. You may want to begin by running a tail command on the `current` log:

    `cd /var/tempest/workspaces/default/deployments/micro`

    If you are unable to resolve an issue by viewing configurations, exploring
logs, or reviewing common problems, you can troubleshoot further by running
BOSH diagnostic commands with the BOSH Command-Line Interface (CLI).

<p class="note"><strong>Note</strong>: Do not manually modify the deployment manifest. Operations Manager will overwrite manual changes to this manifest.
In addition, manually changing the manifest may cause future deployments to
fail.</p>

## <a id='common_probs'></a>Common Problems ##

Compare evidence that you have gathered to the problem descriptions below.
If your problem is covered, try the recommended remediation procedures.

### <a id='reinstall_bosh'></a>BOSH does not reinstall ###

You might want to reinstall BOSH for troubleshooting purposes.
However, if Pivotal CF does not detect any changes, BOSH does not reinstall.
To force a reinstall of BOSH, select **Ops Manager Director > Resource Sizes**
and change a resource value.
For example, you could increase the amount of RAM by 1.

### <a id='time_out'></a>Creating bound missing VMs times out ###

This task happens immediately following package compilation, but before job
assignment to agents.
For example:

<pre class="terminal">
cloud_controller/0: Timed out pinging to f690db09-876c-475e-865f-2cece06aba79 after 600 seconds (00:10:24)
</pre>

This is most likely a NATS issue with the VM in question.
To identify a NATS issue, inspect the agent log for the VM.
Since the BOSH director is unable to reach the BOSH agent, you must access the
VM using another method.
You will likely also be unable to access the VM using TCP.
In this case, access the VM using your virtualization console.

To diagnose:

1. Access the VM using your virtualization console and log in.

1. Navigate to the **Credentials** tab of the **Elastic Runtime** tile and
locate the VM in question to find the **VM credentials**.

1. Become root.

1. Run `cd /var/vcap/bosh/log`.

1. Open the file `current`.

1. First, determine whether the BOSH agent and director have successfully
completed a handshake, represented in the logs as a “ping-pong”:

    <pre class="terminal">
     2013-10-03\_14:35:48.58456 #[608] INFO: Message: {"method"=>"ping", "arguments"=>[],      "reply\_to"=>"director.f4b7df14-cb8f-4214-b668-1660944090e4.19719508-e0dd-4f53-b755-58b6336058ab"}
 2013-10-03\_14:35:48.60182 #[608] INFO: reply\_to:   director.f4b7df14-cb8f-4214-b668-1660944090e4.19719508-e0dd-4f53-b755-58b6336058ab: payload: {:value=>"pong"}
    </pre>

    This handshake must complete for the agent to receive instructions from the
director.

1. If you do not see the handshake, look for another line near the beginning of
the file, prefixed `INFO: loaded new infrastructure settings`.
For example:

     <pre class="terminal">
      2013-10-03\_14:35:21.83222 #[608] INFO: loaded new infrastructure settings: {"vm"=>{"name"=>"vm-4d80ede4-b0a5-4992-aea6-1c6a0386e18e", "id"=>"vm-360"}, "agent\_id"=>"56aea4ef-6aa9-4c39-8019-7024c1cfdde4", "networks"=>{"default"=>{"ip"=>"192.168.86.19", "netmask"=>"255.255.255.0", "cloud\_properties"=>{"name"=>"VMNetwork"}, "default"=>["dns", "gateway"], "dns"=>["192.168.86.2", "192.168.86.17"], "gateway"=>"192.168.86.2", "dns\_record\_name"=>"0.nats.default.cf-d7293430724a2c421061.microbosh", "mac"=>"00:50:56:9b:71:67"}}, "disks"=>{"system"=>0, "ephemeral"=>1, "persistent"=>{}}, "ntp"=>[], "blobstore"=>{"provider"=>"dav", "options"=>{"endpoint"=>"http://192.168.86.17:25250", "user"=>"agent", "password"=>"agent"}}, "mbus"=>"nats://nats:nats@192.168.86.17:4222", "env"=>{"bosh"=>{"password"=>"$6$40f9977ca2abd9d9$v2AIebPPYZflT6B265FkOigsR/8Wt0BiPsS2GDq2BpJoI5cPjWjRK5HJyq3gTZH7zK4i4tQ9K4rvvC/8ADZHW0"}}}
     </pre>

This is a JSON blob of key/value pairs representing the expected infrastructure
for the BOSH agent.
For this issue, the following section is the most important:

`"mbus"=>"nats://nats:nats@192.168.86.17:4222"`

This key/value pair represents where the agent expects the NATS server to be.
One diagnostic tactic is to try pinging this NATS IP address from the VM to
determine whether you are experiencing routing issues.

### <a id='RSA-cert'></a>Install exits with a creates/updates/deletes app failure or with a 403 ###

**Scenario 1:**
Your Pivotal CF install exits with the following 403 error when you attempt to
log in to the Developer Console:

<pre>
{"type": "step_finished", "id": "console.deploy"}

/home/tempest-web/tempest/web/vendor/bundle/ruby/1.9.1/gems/mechanize-2.7.2/lib/mechanize/http/agent.rb:306:in `fetch': 403 => Net::HTTPForbidden for https://login.api.x.y/oauth/authorizeresponse_type=code&client_id=portal&redirect_uri=https%3... -- unhandled response (Mechanize::ResponseCodeError)
</pre>

**Scenario 2:**
Your Pivotal CF install exits with a `creates/updates/deletes an app (FAILED - 1)` error message with the following stack trace:

<pre>
1) App CRUD creates/updates/deletes an app
   Failure/Error: Unable to find matching line from backtrace
   CFoundry::TargetRefused:
     Connection refused - connect(2)
</pre>

In either of the above scenarios, ensure that you have correctly entered your
domains in wildcard format:

1. Browse to the Operations Manager interface IP.

1. Click the **Elastic Runtime** tile.

1. Select **HAProxy** and click **Generate Self-Signed RSA Certificate**.

1. Enter your system and app domains in wildcard format, as well as optionally
any custom domains, and click **Save**.
Refer to **Elastic Runtime > Cloud Controller** for explanations of these
domain values.

 <%= image_tag('rsa_cert.png') %>

### <a id='runtime_depend'></a>Install fails when Gateway instances > 0 ###

If you configure the number of Gateway instances to be greater than zero for a
given product, you create a dependency on Elastic Runtime for that product
installation.
If you attempt to install a product tile with an Elastic Runtime dependency
before installing Elastic Runtime, the install fails.

To change the number of Gateway instances, click the product
tile, then select **Settings > Resource sizes > INSTANCES** and change the
value next to the product Gateway job.

To remove the Elastic Runtime dependency, change the value of this field to `0`.

### <a id='out_of_disk_space'></a>Out of Disk Space Error ###

Pivotal CF displays an `Out of Disk Space` error if log files expand to fill
all available disk space.
If this happens, rebooting the Pivotal CF installation VM clears the tmp
directory of these log files and resolves the error.

### <a id='vsphere_fails'></a>Installing Ops Manager Director fails ###
If the DNS information for the Pivotal CF VM is incorrectly specified when
deploying the Pivotal CF .ova file, installing Ops Manager Director fails at the "Installing Micro BOSH" step.

To resolve this issue, correct the DNS settings in the Pivotal CF Virtual
Machine properties.

### <a id='elastic_runtime_fails'></a>Installing Elastic Runtime fails ###

If the DNS information for the Pivotal CF VM becomes incorrect after Ops Manager Director has been installed, installing Elastic Runtime with Pivotal Operations
Manager fails at the "Verifying app push" step.

To resolve this issue, correct the DNS settings in the Pivotal CF Virtual
Machine properties.

##<a id='console-logs'></a>Viewing Developer Console Logs in a Terminal Window ##

The [Developer Console](../console/dev-console.html) provides a graphical user
interface to help manage organizations, users, applications, and spaces.

When troubleshooting Developer Console performance, you might want to view the
Developer Console application logs.
To view the Developer Console application logs, follow these steps:

1. Run `cf login -a api.MY-SYSTEM-DOMAIN -u admin` from a command line to log
in to Pivotal CF using the UAA Administrator credentials. In Pivotal Ops
Manager, refer to **Pivotal Elastic Runtime > Credentials** for these
credentials.

    <pre class='terminal'>
    $ cf login -a api.example.com -u admin
    API endpoint: api.example.com

    Password>******
    Authenticating...
    OK
    </pre>

1. Run `cf target -o system -s console` to target the `system` org and the
`console` space.

    <pre class='terminal'>
    $ cf target -o system -s console
    </pre>

1. Run `cf logs console` to tail the Developer Console logs.

    <pre class='terminal'>
    $ cf logs console
    Connected, tailing logs for app console in org system / space console as
    admin...
    </pre>

###<a id='changing-log-level'></a>Changing Logging Levels for the Developer Console ##

The Developer Console recognizes the `LOG_LEVEL` environment variable.
The `LOG_LEVEL` environment variable allows you to filter the messages
reported in the Developer Console log files by severity level. The Developer
Console defines severity levels using the Ruby standard library [Logger class](http://www.ruby-doc.org/stdlib-1.9.3/libdoc/logger/rdoc/Logger.html).

By default, the Developer Console `LOG_LEVEL` is set to `info`.
The logs show more verbose messaging when you set the `LOG_LEVEL` to `debug`.

To change the Developer Console `LOG_LEVEL`, run `cf set-env console LOG_LEVEL` with the desired severity level.

<pre class='terminal'>
$ set-env console LOG_LEVEL debug
</pre>

You can set `LOG_LEVEL` to one of the six severity levels defined by the Ruby
Logger class:

* **Level 5**: `unknown` -- An unknown message that should always be logged
* **Level 4**: `fatal` -- An unhandleable error that results in a program crash
* **Level 3**: `error` -- A handleable error condition
* **Level 2**: `warn` -- A warning
* **Level 1**: `info` -- General information about system operation
* **Level 0**: `debug` -- Low-level information for developers

Once set, the Developer Console log files only include messages at the set
severity level and above.
For example, if you set `LOG_LEVEL` to `fatal`, the log includes `fatal` and
`unknown` level messages only.